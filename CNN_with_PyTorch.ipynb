{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdaqpfP7UJOL8lPwZocCCg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahulyadav2310/PyTorch_learningBook/blob/main/CNN_with_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Required **Libraries**"
      ],
      "metadata": {
        "id": "ALRELgeEJ5mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Core PyTorch library\n",
        "import torch\n",
        "\n",
        "# Neural network modules\n",
        "import torch.nn as nn\n",
        "\n",
        "# Optimizers\n",
        "import torch.optim as optim\n",
        "\n",
        "# Dataset and image utilities\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# DataLoader for batching data\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Check PyTorch version and GPU\n",
        "print(torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0jlT4TeJ9jN",
        "outputId": "4524451c-81b5-4f35-9350-fb5bba327600"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cpu\n",
            "CUDA available: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Transformations"
      ],
      "metadata": {
        "id": "PZlzk7OzKDDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert images to tensors\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n"
      ],
      "metadata": {
        "id": "M17nUAmnKR2Q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load MNIST Dataset"
      ],
      "metadata": {
        "id": "ygNiJ9aAKU9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and load training dataset\n",
        "train_dataset = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "# Create DataLoader (batching + shuffling)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "FRmTFA3SKXxL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define CNN Model"
      ],
      "metadata": {
        "id": "XA_PVQeNKafp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Convolution layer 1\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=1,   # grayscale image\n",
        "            out_channels=16, # number of filters\n",
        "            kernel_size=3    # 3x3 filter\n",
        "        )\n",
        "\n",
        "        # Pooling layer\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(16 * 13 * 13, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply convolution + activation\n",
        "        x = torch.relu(self.conv1(x))         #ReLU removes negative values\n",
        "                                             # from the output, allowing the network\n",
        "                                             # to learn non-linear patterns and train faster.\n",
        "\n",
        "        # Apply pooling\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Flatten image into vector\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Final output layer\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "WZB3nX46KejY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Model, Loss, Optimizer"
      ],
      "metadata": {
        "id": "iScsQee1KoLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model object\n",
        "model = CNN()\n",
        "\n",
        "# Loss function for classification\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "oueuA2kRKtj6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop (MOST IMPORTANT)"
      ],
      "metadata": {
        "id": "ZyiAp46NKwhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "for epoch in range(3):\n",
        "    for images, labels in train_loader:\n",
        "\n",
        "        # Forward pass\n",
        "        predictions = model(images)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(predictions, labels)\n",
        "\n",
        "        # Clear previous gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} completed, Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOjT91ryKzAq",
        "outputId": "e14539a7-07e2-46cb-d330-fa249201740f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 completed, Loss: 0.0508\n",
            "Epoch 2 completed, Loss: 0.0506\n",
            "Epoch 3 completed, Loss: 0.2287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation (Prediction)"
      ],
      "metadata": {
        "id": "Ng8h5IHNK1hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Switch model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Disable gradient calculation\n",
        "with torch.no_grad():\n",
        "    sample_image, sample_label = train_dataset[0]\n",
        "    output = model(sample_image.unsqueeze(0))\n",
        "    prediction = torch.argmax(output)\n",
        "\n",
        "    print(\"Predicted digit:\", prediction.item())\n",
        "    print(\"Actual digit:\", sample_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8p0evfeK4dc",
        "outputId": "18220f42-b10e-4c76-ecd1-3e1484fbb1ca"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted digit: 5\n",
            "Actual digit: 5\n"
          ]
        }
      ]
    }
  ]
}